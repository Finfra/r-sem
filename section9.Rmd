---
title: 'Section 9: Structural Equation Modeling (SEM) Continued'
output:
  html_document:
    highlight: pygments
    theme: flatly
    toc: yes
    toc_depth: 2
---

Load in some packages
```{r}
library(ggplot2)
theme_set(theme_bw(base_size = 18))
library(lavaan)
library(semPlot)
library(corrplot)

plot_matrix <- function(matrix_toplot){
corrplot(matrix_toplot, is.corr = FALSE, 
               type = 'lower', 
               order = "original", 
               tl.col='black', tl.cex=.75)
}
```

## Recap of lavaan models

As a note, remember that the numbers of parameters you can estimate depends on the number of variables! If you have k variables, you can estimate $\frac{k*(k-1)}{2}$ parameters. For instance, if you have 3 variables, you can estimate $\frac{3*2}{2} = 3$ parameters. If you have 6 variables, you can estimate $\frac{6*5}{2} = 15$ parameters. Here, we have 7 variables, so we can estimate up to $\frac{7*6}{2} = 21$ parameters (though we'll probably need fewer!).

Similar to `lm()` and `lmer()`, etc., the model format has the DV on the left side of the operator, and the IV on the right side. In terms of the structural diagram, you could think of the arrow going from right to left. When the operator is a `~` this is regression, such that the DV(s) are "predicted by" the IV(s). When the operator is `=~` we are defining a latent variable, reading it like L is "measured by" IVs. Variances/covariances are specified with a `~~` (e.g., DV is "correlated with" DV), and intercepts are simple regression formulas with `1` as the predictor. We include all these formulas inside **single quotes**.

- **Regressions**
    - Y is predicted by X1 and X2: `Y ~ X1 + X2`
    - Y1 is predicted by X1, and Y2 is predicted by X1: `Y1 + Y2 ~ X1`

- **Latent Variables**
    - Latent variable L is measured by variables U and V: `L =~ U + V`

- **Variances & covariances**
    - The variance of X: `X ~~ X`
    - The covariance of X and Y1: `X ~~ Y1`
    - The covariance of X and Y2 is fixed at 0: `X ~~ 0*Y2`
    
- **Intercepts**
    - The intercept of X: `X ~ 1`

For some practice generating the structural plot and equations, go [here](http://www.stanford.edu/class/psych253/section/section_8/example_lavaan.html)!


## Question B: Adding regression coefficients
Here, Sadler & Woody (2003) test an interpersonal theory of dyadic interaction: Person M’s 'behavior' when interacting with person F (i.e., M’s situational behavior) is influenced by (i) M’s long-term tendency to elicit the behavior (i.e., M’s behavioral trait), and (ii) F’s situational behavior. The same is assumed true for F. 

The four variables, trait and behavior for each of M and F, are represented as **latent variables** that can be measured in multiple ways. "Reciprocal influence" is conceptualized as M’s situational behavior influencing F’s situational behavior, and vice versa. In this study, M and F were strangers, so M’s trait (which is unknown to F) couldn't affect F’s situational behavior. However, if M and F were friends, such links would be expected to be significant and should be included in the model. Trait is measured by self-report and a friend’s report; and situational behavior is rated by self, partner and an observer. Rater biases are introduced through the use of covariance arrows.

### Variable coding:
1. Female or male (M/F)
2. Situational or trait (S/T)
3. Observer, partner, friend, or self rating (O/I/F/S)
4. Rating (R)

### Load in data

```{r}
low.dom = '
1
.415 1
.460 .351 1
-.321 -.374 -.310 1
-.239 -.221 -.133 .626 1
-.185 -.164 -.272 .533 .345 1
.349 .307 .496 -.180 -.081 -.067 1
.308 .302 .562 -.222 -.156 -.118 .573 1
.038 -.115 -.048 .296 .167 .320 .008 -.036 1
-.072 -.160 -.124 .317 .167 .248 -.152 -.175 .414 1 
'

labels1 = c("FSOR", "FSIR", "FSSR", "MSOR", "MSIR", "MSSR", "FTFR", "FTSR", "MTSR", "MTFR")
dom.cov = getCov(low.dom, names = labels1)
plot_matrix(dom.cov)
```

### Segue about directionality!
```{r}
dyad.ex1 = '
  FSSR ~ FTSR
'
dyad.ex2 = '
  FTSR ~ FSSR
'

dyad.fit_ex1 = sem(dyad.ex1, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112)
# parameterEstimates(dyad.fit_ex1) 

dyad.fit_ex2 = sem(dyad.ex2, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112)
# parameterEstimates(dyad.fit_ex2) 

anova(dyad.fit_ex1, dyad.fit_ex2)
```

```{r}
dyad.ex1 = '
  FSSR ~ FTSR
  FSSR ~ MSSR
'
dyad.ex2 = '
  FTSR ~ FSSR
  FSSR ~ MSSR
'

dyad.fit_ex1 = sem(dyad.ex1, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112)
# parameterEstimates(dyad.fit_ex1) 

dyad.fit_ex2 = sem(dyad.ex2, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112)
# parameterEstimates(dyad.fit_ex2) 

anova(dyad.fit_ex1, dyad.fit_ex2)
```

Here, the estimates have changed slightly, but also note the addition of a covariance between `FTSR ~~ MSSR` into the first model! The variance estimates have also changed slightly.

### Unconstrained paths

Here, we have latent variables that are measured by observed variables. Specifically, female trait dominance (FTZ) is measured by friends and self trait ratings (FTSR and FTFT). Similarly, female situational dominance (FSZ) is measured by self, partner, and observers' ratings. The same is true for males. Thus, we'll have to define these latent variables in the model, and then see how these latent variables are predicted by other latent variables!

We want to estimate the paths A and B (the effect of the individuals' traits on their situational behavior) and C and D (the effects of individuals' situational behavior on each other). Let's first allow these paths to be unconstrained (i.e., we can get a different estimate for each path).

Using the `*` operator below "names" the regression coefficient. This is useful mainly because if we give to coefficients the same name, the function automatically constrains them to be the same.


```{r}
dyad.model1 = '
  # Latent variable definitions for trait, FTZ & MTZ, and situation, FSZ & MSZ	
	FTZ =~ FTSR + FTFR
	MTZ =~ MTSR + MTFR
	FSZ =~ FSSR + FSIR + FSOR
	MSZ =~ MSSR + MSIR + MSOR
	
	# regressions
	FSZ ~ B*FTZ + C*MSZ
	MSZ ~ A*MTZ + D*FSZ
	 
	# variances and covariances
	# Residual correls among M ratings, MTSR, MSSR, FSIR
	MTSR + MSSR ~~ FSIR
	MSSR ~~ MTSR
	
	# Residual correls among F ratings, FTSR, FSSR, MSIR
	FTSR + FSSR ~~ MSIR
	FSSR ~~ FTSR
	
	# Residual correls among Observer situational ratings, MSOR, FSOR	
	MSOR ~~ FSOR	
'
```

```{r}
dyad.fit1 = sem(dyad.model1, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112)
print(dyad.fit1) #good p value
summary(dyad.fit1, fit.measures = TRUE)
parameterEstimates(dyad.fit1) #good p value
```

Note that for each latent variable, the path from the latent variable to one of its indicator variables is assigned the value of 1.0! By default this is the first variable specified in the `{lavaan}` model. Given this constraint, the remaining paths (i.e., the paths from the latent variable to the other indicators) can then be estimated. The indicator selected to be constrained to 1.0 is the **reference item**. Typically one selects as the reference item the one which in factor analysis loads most heavily on the dimension represented by the latent variable, thereby allowing it to anchor the meaning of that dimension.

#### Visualize the standardized paths
```{r}
semPaths(dyad.fit1, what='std', 
         node.label.cex=5,
         edge.label.cex=1.25, curvePivot = TRUE, 
         fade=FALSE)
```

Note that the semPaths function here is showing the standardized parameter estimates -- we can get those here:
```{r}
standardizedSolution(dyad.fit1)
```

These parameter estimates are **standardized**, basically meaning that the **factor variances are set to 1**. Here, you can see that the path from the latent variable to the one of its indicator variables that *had* been assigned the value of 1.0 above (i.e., in the unstandardized solution) is no longer 1.0! In ho-5-SEM2.pdf Ewart notes that "**cross-group comparisons of standardized path coefficients** are **NOT recommended** as this confounds differences in strength of relationship with differences in the ratio of independent to dependent variable variances"!


#### Assess model
```{r}
plot_matrix(residuals(dyad.fit1)$cov)

mi = modificationIndices(dyad.fit1)
head(mi[order(-mi$mi), ], 10)
```

This model is ok, but let's see if we can get a simpler model that works! Let's try taking out most of the covariance terms.

```{r}
dyad.model2 = '
  # Latent variable definitions for trait, FTZ & MTZ, and situation, FSZ & MSZ	
	FTZ =~ FTSR + FTFR
	MTZ =~ MTSR + MTFR
	FSZ =~ FSSR + FSIR + FSOR
	MSZ =~ MSSR + MSIR + MSOR
	
	# regressions
	FSZ ~ B*FTZ + C*MSZ
	MSZ ~ A*MTZ + D*FSZ
	 
	# Residual correls among M ratings, MTSR, MSSR
	MSSR ~~ MTSR
	
	# Residual correls among F ratings, FTSR, FSSR
	FSSR ~~ FTSR
'
dyad.fit2 = sem(dyad.model2, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112) 
print(dyad.fit2) # Wow, even better !

parameterEstimates(dyad.fit2)
anova(dyad.fit1,dyad.fit2)
```

This simpler model is definitely the better one! We have more dfs for model testing (fewer parameters estimated), a lower AIC, and then $\chi^2$ isn't significantly worse!

### Constrained paths
Let's see if we need our "C" and "D" paths to be different. We have 1 less parameter to estimate if we constrain them to be the same, so it would be more parsimonious if we can have a constrained model!

```{r}
dyad.model3 = '
  # Latent variable definitions for trait, FTZ & MTZ, and situation, FSZ & MSZ	
	FTZ =~ FTSR + FTFR
	MTZ =~ MTSR + MTFR
	FSZ =~ FSSR + FSIR + FSOR
	MSZ =~ MSSR + MSIR + MSOR
	
	# regressions
	FSZ ~ B*FTZ + C*MSZ
	MSZ ~ A*MTZ + C*FSZ
	 
	# Residual correls among M ratings, MTSR, MSSR
	MSSR ~~ MTSR
	
	# Residual correls among F ratings, FTSR, FSSR
	FSSR ~~ FTSR
'

dyad.fit3 = sem(dyad.model3, fixed.x = T, sample.cov = dom.cov, sample.nobs = 112) #notice how i set fixed.x = T here so it wouldn't automatically add terms I didn't want
print(dyad.fit3)
parameterEstimates(dyad.fit3)
anova(dyad.fit1,dyad.fit2,dyad.fit3) #looks like constraining it made the model better! So they probably aren't actually different

parameterEstimates(dyad.fit3)

#could also test it this way:
dyad.fit3a = sem(dyad.model2, fixed.x = F, sample.cov = dom.cov, sample.nobs = 112, constraints = 'C - D == 0', start = dyad.fit2) #using our model2 design, but constraining C-D to be 0 (i.e., C = D)
# summary(dyad.fit3a) #same result as before
```

## Question C: Group Comparisons

For this question, we assess Prof Jeanne Tsai's "Affect Valuation Theory" (AVT), about the antecedents and consequences of ideal affect, and how it might vary across cultures. Specifically, this theory hypothesizes that culture influences ideal affect more than actual affect, whereas temperament/personality influences actual affect more than ideal affect. Further, engaging in rigorous activities is more strongly predicted by ideal affect, but depression is more predicted by actual affect. In addition, culture (Asian American, Hong Kong Chinese, and European American / AA, CH, EA) might influences these processes.

To start out, let's specify the model for the whole sample, ignoring 'group'.

```{r}
d = read.csv("http://www.stanford.edu/class/psych253/data/jt-data1.csv")
str(d)

avt.model1 = '
  # regressions	
	ideahap + actuhap ~ cultatt + temperatt
	rigoract + depress ~ ideahap + actuhap + cultatt + temperatt
	
	# variances and covariances
	rigoract ~~ 0*depress
'

avt.fit1 = sem(avt.model1, fixed.x = F, data = d)
summary(avt.fit1)
```

Model 1 is almost saturated - only 2 df is left for testing - yet it is poor. This suggests that many of the paths are unhelpful, i.e., have coeffs near 0. These unhelpful paths should be removed and replaced by useful paths. I was surprised that sem() estimated cov(rigoract, depress), because these vars are not exogenous. It appears that sem(), by default, puts a cov path between any pair of variables that are not already linked in the model! This is a waste of params, so explicitly set these unwanted cov paths equal to 0. 

A common finding in this field is that ideal HAP and actual HAP are correlated. So introduce a cov link between them.

```{r}
#This model removes the paths with low p-values, and adds the new covariance
avt.model2 = '
  # regressions
	# X + Y ~ U + V + W
	
	ideahap + actuhap ~ cultatt + temperatt
	rigoract ~ ideahap + temperatt
	depress ~ actuhap + temperatt
	
	# variances and covariances
	# X ~~ Y
	rigoract ~~ 0*depress
	ideahap ~~ actuhap
'
avt.fit2 = sem(avt.model2, fixed.x = F, data = d)
summary(avt.fit2) #much better!    
anova(avt.fit1, avt.fit2)
```

### Group analysis
Now, we might wonder if the model we specified above applies to any one of the three groups (EA, AA, and CH).

```{r}
grplab1 = c("EA", "AA", "CH")
d$group = factor(d$group, labels = grplab1)
str(d$group)

avt.group1 = sem(avt.model2, fixed.x = F, data = d, group = "group", meanstructure = F)
summary(avt.group1)
```
The fit to each group is acceptable when the parameters were free to vary across groups, except that the fit to Group 1 is almost significant ($\chi^2$ = 9.8 with 5 df, p = `r round(pchisq(9.8, df = 5, lower.tail = FALSE), 2)`). 

What if we were to equate params across groups?

```{r}
avt.group2 = sem(avt.model2, fixed.x = F, data = d, group = "group", meanstructure = F, group.equal = "regressions")
summary(avt.group2)
anova(avt.group1,avt.group2)
```

The constrained model is not significantly worse, and it has a lower AIC. So prefer it! The sample sizes in this data set are 'small' for SEM, and this is one reason why different models are not significantly different - not enough power to make the distinctions.


#### Impose equality constraints in unconstrained model

Let us continue with model refinement purely to see how this might be done in the general case. We can start with the unconstrained model, and then impose equality constraints on params. Or we can start with the constrained model, and then relax the equality constraints. Let's start by imposing equality constraints in the unconstrained model.

```{r}
#this one constrains cultatt to be the same across both groups, but lets temperatt to be different
avt.model3 = '
  # regressions
	# X + Y ~ U + V + W
	# Effect of cultatt on ideal hap, and on actual hap, same across cultures
	# Effect of temperatt on ideal hap, and on actual hap, different across cultures
	# All other params differ across cultures
	
	ideahap ~ c(k1, k1, k1)*cultatt + c(l1, l2, l3)*temperatt
	actuhap ~ c(k4, k4, k4)*cultatt + c(l4, l5, l6)*temperatt
	rigoract ~ ideahap + temperatt
	depress ~ actuhap + temperatt
	
	# variances and covariances
	# X ~~ Y
	rigoract ~~ 0*depress
	ideahap ~~ actuhap
'
avt.group3 = sem(avt.model3, fixed.x = F, data = d, group = "group", meanstructure = F)
summary(avt.group3)
anova(avt.group1, avt.group3) #debatable whether that's actually a good thing or not
```

Since we had a bad fit for our EA (group 1), what if we estimate separate parameters for EA, but constrain Asian Americans (group2) and Hong Kong Chinese (group3) to be the same?
```{r}
#this one constrains cultatt to be the same across both groups, but lets temperatt to be different
avt.model3b = '
  # regressions
  # X + Y ~ U + V + W
	# Effect of cultatt on ideal hap, and on actual hap, same across cultures
	# Effect of temperatt on ideal hap, and on actual hap, different across cultures
	# All other params differ across cultures
	
	ideahap ~ c(k1, k2, k2)*cultatt + c(l1, l2, l3)*temperatt
	actuhap ~ c(k4, k5, k5)*cultatt + c(l4, l5, l6)*temperatt
	rigoract ~ ideahap + temperatt
	depress ~ actuhap + temperatt
	
	# variances and covariances
	# X ~~ Y
	rigoract ~~ 0*depress
	ideahap ~~ actuhap
'

avt.group3b = sem(avt.model3b, fixed.x = F, data = d, group = "group", meanstructure = F)
summary(avt.group3b)
anova(avt.group1, avt.group3b) #this is better!
```


#### Relax equality constraints in constrained model

Here we'll allow effect of temperatt on ideahap and on actuhap to vary across cultures. The `group.partial` command overrides the default behavior of the `group.equal` parameter, letting those particular regressions vary across cultures
```{r}
avt.group4 = sem(avt.model2, fixed.x = F, data = d, group = "group", meanstructure = F, group.equal = "regressions", group.partial = c("ideahap ~ temperatt", "actuhap ~ temperatt"))
anova(avt.group2, avt.group4) 
```

Again, debatable which is better...but see the analysis above letting just EA vary!
